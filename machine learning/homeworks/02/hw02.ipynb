{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California housing dataset\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MedInc',\n",
       " 'HouseAge',\n",
       " 'AveRooms',\n",
       " 'AveBedrms',\n",
       " 'Population',\n",
       " 'AveOccup',\n",
       " 'Latitude',\n",
       " 'Longitude']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a common seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate the model with different gradient descent variants\n",
    "def train_evaluate_gd_model(learning_type=\"batch\", batch_size=32, max_iter=1000):\n",
    "    if learning_type == \"batch\":\n",
    "        # Batch Gradient Descent (default SGD with large batch size)\n",
    "        model = SGDRegressor(max_iter=max_iter, tol=1e-3, learning_rate=\"constant\", eta0=0.01, random_state=42)\n",
    "    elif learning_type == \"mini_batch\":\n",
    "        # Mini-Batch Gradient Descent\n",
    "        model = SGDRegressor(max_iter=max_iter, tol=1e-3, learning_rate=\"constant\", eta0=0.01, random_state=42)\n",
    "    elif learning_type == \"stochastic\":\n",
    "        # Stochastic Gradient Descent (effectively SGD with batch size = 1)\n",
    "        model = SGDRegressor(max_iter=max_iter, tol=1e-3, learning_rate=\"constant\", eta0=0.01, random_state=42)\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate Mean Squared Error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error with Batch Gradient Descent: 5.972164660548314e+20\n",
      "Mean Squared Error with Mini-Batch Gradient Descent: 5.972164660548314e+20\n",
      "Mean Squared Error with Stochastic Gradient Descent: 5.972164660548314e+20\n"
     ]
    }
   ],
   "source": [
    "# Run experiments for each gradient descent type\n",
    "mse_batch = train_evaluate_gd_model(learning_type=\"batch\")\n",
    "mse_mini_batch = train_evaluate_gd_model(learning_type=\"mini_batch\")\n",
    "mse_stochastic = train_evaluate_gd_model(learning_type=\"stochastic\")\n",
    "\n",
    "print(\"Mean Squared Error with Batch Gradient Descent:\", mse_batch)\n",
    "print(\"Mean Squared Error with Mini-Batch Gradient Descent:\", mse_mini_batch)\n",
    "print(\"Mean Squared Error with Stochastic Gradient Descent:\", mse_stochastic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate model with specific batch size, learning rate, and max iterations\n",
    "def train_evaluate_gd_model(batch_size, max_iter, eta):\n",
    "    model = SGDRegressor(max_iter=max_iter, tol=1e-3, learning_rate=\"constant\", eta0=eta, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for each gradient descent variant\n",
    "batch_params = {'batch_size': len(X_train), 'max_iter': 1000, 'eta': 0.001}    # Batch GD with low learning rate\n",
    "mini_batch_params = {'batch_size': 32, 'max_iter': 500, 'eta': 0.01}           # Mini-Batch GD with medium learning rate\n",
    "stochastic_params = {'batch_size': 1, 'max_iter': 100, 'eta': 0.1}             # SGD with higher learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for each gradient descent variant\n",
    "batch_mse = train_evaluate_gd_model(**batch_params)\n",
    "mini_batch_mse = train_evaluate_gd_model(**mini_batch_params)\n",
    "stochastic_mse = train_evaluate_gd_model(**stochastic_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error with Batch Gradient Descent: 3640814.487722178\n",
      "Mean Squared Error with Mini-Batch Gradient Descent: 5.972164660547045e+20\n",
      "Mean Squared Error with Stochastic Gradient Descent: 2.727525622991196e+21\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Mean Squared Error with Batch Gradient Descent:\", batch_mse)\n",
    "print(\"Mean Squared Error with Mini-Batch Gradient Descent:\", mini_batch_mse)\n",
    "print(\"Mean Squared Error with Stochastic Gradient Descent:\", stochastic_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d0e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, precision_score, roc_curve, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c974422",
   "metadata": {},
   "source": [
    "Graph Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d186bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_graph(G, train_frac=0.8, test_frac=0.1, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    edges = list(G.edges())\n",
    "    np.random.shuffle(edges)\n",
    "    m = len(edges)\n",
    "    n_train = int(train_frac * m)\n",
    "    n_test = int(test_frac * m)\n",
    "\n",
    "    train_edges = edges[:n_train]\n",
    "    test_pos = edges[n_train:n_train + n_test]\n",
    "\n",
    "    G_train = nx.Graph()\n",
    "    G_train.add_nodes_from(G.nodes())\n",
    "    G_train.add_edges_from(train_edges)\n",
    "\n",
    "    non_edges = list(nx.non_edges(G_train))\n",
    "    np.random.shuffle(non_edges)\n",
    "    test_neg = non_edges[:n_test]\n",
    "\n",
    "    return G_train, test_pos, test_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edb415",
   "metadata": {},
   "source": [
    "Scoring methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf381f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_method(G_train, u, v, method):\n",
    "    if method == 'common_neighbors':\n",
    "        return len(list(nx.common_neighbors(G_train, u, v)))\n",
    "    if method == 'jaccard':\n",
    "        return next(nx.jaccard_coefficient(G_train, [(u, v)]))[2]\n",
    "    if method == 'adamic_adar':\n",
    "        return next(nx.adamic_adar_index(G_train, [(u, v)]))[2]\n",
    "    if method == 'pref_attachment':\n",
    "        return next(nx.preferential_attachment(G_train, [(u, v)]))[2]\n",
    "    if method == 'resource_allocation':\n",
    "        return next(nx.resource_allocation_index(G_train, [(u, v)]))[2]\n",
    "    raise ValueError(f\"Unknown method {method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421a6dba",
   "metadata": {},
   "source": [
    "Method evaluation with detailed scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_method(G_train, test_pos, test_neg, method):\n",
    "    pairs = test_pos + test_neg\n",
    "    y_true = np.array([1]*len(test_pos) + [0]*len(test_neg))\n",
    "    scores = np.array([score_method(G_train, u, v, method) for u, v in pairs])\n",
    "\n",
    "    # ROC AUC\n",
    "    auc_score = roc_auc_score(y_true, scores)\n",
    "    # ROC curve data\n",
    "    fpr, tpr, _ = roc_curve(y_true, scores)\n",
    "\n",
    "    # Precision-Recall AUC\n",
    "    precision_vals, recall_vals, _ = precision_recall_curve(y_true, scores)\n",
    "    pr_auc = auc(recall_vals, precision_vals)\n",
    "\n",
    "    # Precision@k\n",
    "    k = len(test_pos)\n",
    "    idx_top = np.argsort(scores)[::-1][:k]\n",
    "    y_pred_top = np.zeros_like(y_true)\n",
    "    y_pred_top[idx_top] = 1\n",
    "    precision_k = precision_score(y_true, y_pred_top)\n",
    "\n",
    "    return {\n",
    "        'method': method,\n",
    "        'AUC': auc_score,\n",
    "        'PR_AUC': pr_auc,\n",
    "        'Precision@k': precision_k,\n",
    "        'fpr': fpr,\n",
    "        'tpr': tpr,\n",
    "        'precision_curve': precision_vals,\n",
    "        'recall_curve': recall_vals\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
